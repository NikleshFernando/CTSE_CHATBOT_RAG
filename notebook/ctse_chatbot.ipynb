{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfb57ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Introduction to the AWS Cloud \n",
      "Platform\n",
      "Ravindu Nirmal Fernando\n",
      "2x AWS Community Builder | STL @ Sysco LABS\n",
      "Agenda\n",
      "â€¢ Introduction to AWS cloud platform and its benefits\n",
      "â€¢ AWS Global Infrastructure\n",
      "â€¢ Accessing AWS Services\n",
      "â€¢ Interacting with AWS Services\n",
      "â€¢ Best Practices for managing AWS Accounts\n",
      "â€¢ Common AWS services\n",
      "â€¢ Demo\n",
      "What is AWS Cloud?\n",
      "â€¢ AWS Cloud is a cloud computing \n",
      "platform that provides a wide range of \n",
      "services, including compute, storage, \n",
      "databases, security, networking, \n",
      "analytic\n"
     ]
    }
   ],
   "source": [
    "import fitz  \n",
    "import os\n",
    "\n",
    "def extract_all_pdf_text(pdf_folder):\n",
    "    combined_text = \"\"\n",
    "    for filename in sorted(os.listdir(pdf_folder)):\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            path = os.path.join(pdf_folder, filename)\n",
    "            doc = fitz.open(path)\n",
    "            for page in doc:\n",
    "                combined_text += page.get_text()\n",
    "            combined_text += \"\\n\\n\"\n",
    "    return combined_text\n",
    "\n",
    "raw_text = extract_all_pdf_text(\"../data/\")\n",
    "print(raw_text[:500])  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d604bd02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 4891, which is longer than the specified 500\n",
      "Created a chunk of size 5186, which is longer than the specified 500\n",
      "Created a chunk of size 5328, which is longer than the specified 500\n",
      "Created a chunk of size 3674, which is longer than the specified 500\n",
      "Created a chunk of size 4093, which is longer than the specified 500\n",
      "Created a chunk of size 16000, which is longer than the specified 500\n",
      "Created a chunk of size 5647, which is longer than the specified 500\n",
      "Created a chunk of size 8128, which is longer than the specified 500\n",
      "Created a chunk of size 12000, which is longer than the specified 500\n",
      "Created a chunk of size 12330, which is longer than the specified 500\n",
      "Created a chunk of size 9734, which is longer than the specified 500\n",
      "Created a chunk of size 2422, which is longer than the specified 500\n",
      "Created a chunk of size 11701, which is longer than the specified 500\n",
      "Created a chunk of size 8563, which is longer than the specified 500\n",
      "Created a chunk of size 9864, which is longer than the specified 500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunks created: 15\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "documents = splitter.create_documents([raw_text])\n",
    "print(f\"Chunks created: {len(documents)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "039f4b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4q/b19qv8r52lx5_bfplnjf1cjw0000gn/T/ipykernel_32514/3897068503.py:12: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vectordb.persist()\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "embedding_function = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embedding_function,\n",
    "    persist_directory=\"../chroma_db\"\n",
    ")\n",
    "\n",
    "vectordb.persist() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02a79af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "\n",
    "llm = Ollama(model=\"mistral\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a3995e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctse_chatbot(query, k=3):\n",
    "    retriever = vectordb.as_retriever(search_kwargs={\"k\": k})\n",
    "    docs = retriever.get_relevant_documents(query)\n",
    "    context = \"\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "Use the following CTSE lecture notes to answer the question.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "    return llm.invoke(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fad63d76",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import scrolledtext\n",
    "\n",
    "def submit_query():\n",
    "    query = input_box.get()\n",
    "    if query.strip().lower() in [\"exit\", \"quit\"]:\n",
    "        window.destroy()\n",
    "        return\n",
    "\n",
    "    response = ctse_chatbot(query)\n",
    "    output_box.insert(tk.END, f\"You: {query}\\n\", \"user\")\n",
    "    output_box.insert(tk.END, f\"Bot: {response.strip()}\\n\\n\", \"bot\")\n",
    "    input_box.delete(0, tk.END)\n",
    "\n",
    "window = tk.Tk()\n",
    "window.title(\"ðŸ§  CTSE Chatbot\")\n",
    "\n",
    "input_box = tk.Entry(window, width=80)\n",
    "input_box.pack(padx=10, pady=10)\n",
    "\n",
    "ask_button = tk.Button(window, text=\"Ask\", command=submit_query)\n",
    "ask_button.pack()\n",
    "\n",
    "output_box = scrolledtext.ScrolledText(window, width=90, height=20, wrap=tk.WORD)\n",
    "output_box.pack(padx=10, pady=10)\n",
    "\n",
    "output_box.tag_config(\"user\", foreground=\"blue\")\n",
    "output_box.tag_config(\"bot\", foreground=\"green\")\n",
    "\n",
    "window.mainloop()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
